
# PROJECT 3: ML-Enhanced Ship Fuel Prediction
## ğŸ“‹ Cahier des Charges

### Objectif Principal
DÃ©velopper un modÃ¨le hybride (physique + ML) pour prÃ©dire la consommation de carburant avec quantification d'incertitude.

### ResponsabilitÃ©s du Poste VisÃ©es
- âœ… Machine Learning for predictive modeling (PREFERRED skill)
- âœ… Data Analysis
- âœ… Model Validation

### Livrables
1. **Comparaison de modÃ¨les ML** (Linear, XGBoost, Neural Network)
2. **ModÃ¨le hybride** physique + ML
3. **Quantification d'incertitude** (intervals de confiance)
4. **Feature importance analysis**
5. **API de prÃ©diction** (FastAPI)

### SpÃ©cifications Techniques

#### DonnÃ©es

**Option A: Dataset Kaggle** (RECOMMANDÃ‰)
- **"Propulsion Plant Data Set"** (UCI/Kaggle)
  - 11k observations de propulsion navale
  - Features: vitesse, couple, decay coefficient, etc.
  - Target: consommation fuel

- **"Ship Fuel Consumption Prediction"** (Kaggle)
  - Plusieurs datasets disponibles
  - Features mÃ©tÃ©o + opÃ©rationnels

**Option B: DonnÃ©es SynthÃ©tiques**
```python
# GÃ©nÃ©rer avec modÃ¨le physique + bruit
features = {
    'speed': [5-25 knots],
    'displacement': [10k-20k tonnes],
    'draft': [6-10m],
    'wind_speed': [0-30 m/s],
    'wave_height': [0-8m],
    'trim': [-2, +2 m]
}

target = 'fuel_rate'  # tonnes/hour
```

#### Architecture des ModÃ¨les

**1. Baseline Physique** (si donnÃ©es synthÃ©tiques)
```python
# Utiliser formule simplifiÃ©e comme baseline
fuel_physics = k * VÂ³ * f(displacement, weather)
```

**2. ModÃ¨les ML Ã  Comparer**

```python
# Linear Regression (baseline ML)
from sklearn.linear_model import Ridge, Lasso

# Gradient Boosting (meilleur pour non-linÃ©aritÃ©s)
from xgboost import XGBRegressor

# Neural Network
from sklearn.neural_network import MLPRegressor
# ou PyTorch pour plus de contrÃ´le
```

**3. ModÃ¨le Hybride** (KEY INNOVATION)
```python
# Approche 1: RÃ©sidus
fuel_pred = fuel_physics + ML_model(features)

# Approche 2: Feature engineering
features_augmented = [..., fuel_physics, ...]
fuel_pred = ML_model(features_augmented)
```

#### Quantification d'Incertitude

**MÃ©thode 1: Quantile Regression**
```python
# PrÃ©dire percentiles 5%, 50%, 95%
from xgboost import XGBRegressor

model_q50 = XGBRegressor(objective='reg:squarederror')
model_q05 = XGBRegressor(objective='reg:quantileerror', quantile_alpha=0.05)
model_q95 = XGBRegressor(objective='reg:quantileerror', quantile_alpha=0.95)
```

**MÃ©thode 2: Bootstrapping**
```python
# EntraÃ®ner N modÃ¨les sur subsamples
predictions = [model_i.predict(X) for model_i in models]
mean_pred = np.mean(predictions, axis=0)
std_pred = np.std(predictions, axis=0)
```

**MÃ©thode 3: Neural Network avec incertitude**
```python
# Dropout Ã  l'infÃ©rence (MC Dropout)
# ou Gaussian Process layers
```

#### MÃ©triques de Performance

**PrÃ©cision:**
- RMSE, MAE, RÂ²
- MAPE (Mean Absolute Percentage Error)

**Incertitude:**
- Calibration plot (predicted uncertainty vs. actual error)
- Coverage: % de vrais points dans intervals de confiance
- Sharpness: largeur moyenne des intervals

**Feature Importance:**
- SHAP values (pour interprÃ©tabilitÃ©)
- Permutation importance

### Workflow ML

```python
# 1. Split data
train, val, test = split(data, ratios=[0.7, 0.15, 0.15])

# 2. Feature engineering
features_engineered = create_features(raw_data)

# 3. Train models
models = {
    'linear': Ridge(),
    'xgboost': XGBRegressor(),
    'nn': MLPRegressor(),
    'hybrid': HybridModel()
}

# 4. Hyperparameter tuning (validation set)
best_params = tune(model, val_set)

# 5. Final evaluation (test set)
results = evaluate(model, test_set)

# 6. Uncertainty analysis
intervals = predict_with_uncertainty(model, test_set)
```

### API Deployment (Bonus)

```python
# FastAPI endpoint
from fastapi import FastAPI

app = FastAPI()

@app.post("/predict")
def predict_fuel(
    speed: float,
    displacement: float,
    wind_speed: float,
    ...
):
    prediction = model.predict(features)
    uncertainty = compute_uncertainty(features)
    return {
        "fuel_rate": prediction,
        "confidence_interval": [lower, upper]
    }
```

### Structure de Code
```
project_3_ml_fuel_prediction/
â”œâ”€â”€ README.md
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Dataset Kaggle
â”‚   â”œâ”€â”€ processed/           # AprÃ¨s preprocessing
â”‚   â””â”€â”€ README.md            # Data dictionary
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ baseline.py
â”‚   â”‚   â”œâ”€â”€ xgboost_model.py
â”‚   â”‚   â”œâ”€â”€ neural_net.py
â”‚   â”‚   â””â”€â”€ hybrid_model.py
â”‚   â”œâ”€â”€ uncertainty.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ main.py          # FastAPI app
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_model_training.ipynb
â”‚   â”œâ”€â”€ 03_uncertainty_analysis.ipynb
â”‚   â””â”€â”€ 04_results.ipynb
â”œâ”€â”€ models/
â”‚   â””â”€â”€ trained/             # Saved models
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_models.py
â””â”€â”€ requirements.txt
```

### Visualisations Attendues

1. **Predicted vs. Actual** (scatter plot)
2. **Residuals analysis**
3. **Feature importance** (SHAP waterfall)
4. **Uncertainty visualization** (prediction intervals)
5. **Learning curves** (train/val loss)
6. **Model comparison table**

### Datasets Kaggle RecommandÃ©s

1. **"Propulsion Plant Data Set"** â­ BEST MATCH
   - UCI Machine Learning Repository
   - Real ship propulsion data
   - https://www.kaggle.com/datasets/uciml/propulsion-plant-data-set

2. **"Ship Fuel Consumption"**
   - Chercher sur Kaggle: "ship fuel" ou "vessel fuel"
   - Plusieurs datasets disponibles

3. **Alternative: CrÃ©er synthÃ©tique**
   - Avantage: contrÃ´le total, vÃ©ritÃ© terrain connue
   - Utiliser Project 0 pour gÃ©nÃ©rer

### CritÃ¨res de SuccÃ¨s

1. ModÃ¨le hybride meilleur que ML pur ou physique pur
2. Incertitudes calibrÃ©es (90% CI contient ~90% des points)
3. Feature importance cohÃ©rente avec physique
4. API fonctionnelle (bonus)

### Timeline
- **Semaine 1:** EDA, preprocessing, modÃ¨les baseline
- **Semaine 2:** ModÃ¨les avancÃ©s, incertitude, API

---

